{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10558654,"sourceType":"datasetVersion","datasetId":6532454},{"sourceId":10609885,"sourceType":"datasetVersion","datasetId":6568265}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/GianpieroTulipani/SmilesMVP.git\n%cd SmilesMVP\n\n!pip install torch-geometric==1.7.2\n!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n!pip install deepchem\n!pip install loguru\n!pip install ase\n\n%cd smilesmvp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T13:43:24.060047Z","iopub.execute_input":"2025-01-29T13:43:24.060349Z","iopub.status.idle":"2025-01-29T13:43:59.326250Z","shell.execute_reply.started":"2025-01-29T13:43:24.060321Z","shell.execute_reply":"2025-01-29T13:43:59.325271Z"},"editable":false},"outputs":[{"name":"stdout","text":"Cloning into 'SmilesMVP'...\nremote: Enumerating objects: 409, done.\u001b[K\nremote: Counting objects: 100% (135/135), done.\u001b[K\nremote: Compressing objects: 100% (87/87), done.\u001b[K\nremote: Total 409 (delta 117), reused 66 (delta 48), pack-reused 274 (from 1)\u001b[K\nReceiving objects: 100% (409/409), 11.29 MiB | 38.40 MiB/s, done.\nResolving deltas: 100% (325/325), done.\n/kaggle/working/SmilesMVP\nCollecting torch-geometric==1.7.2\n  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.0/223.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (3.4.2)\nRequirement already satisfied: python-louvain in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (0.16)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (1.2.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (2.32.3)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (2.2.2)\nCollecting rdflib (from torch-geometric==1.7.2)\n  Downloading rdflib-7.1.3-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (0.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (3.1.4)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==1.7.2) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==1.7.2) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric==1.7.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric==1.7.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric==1.7.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric==1.7.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric==1.7.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric==1.7.2) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-geometric==1.7.2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-geometric==1.7.2) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-geometric==1.7.2) (2024.2)\nCollecting isodate<1.0.0,>=0.7.2 (from rdflib->torch-geometric==1.7.2)\n  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==1.7.2) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==1.7.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==1.7.2) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==1.7.2) (2024.12.14)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==1.7.2) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==1.7.2) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->torch-geometric==1.7.2) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric==1.7.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric==1.7.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric==1.7.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric==1.7.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric==1.7.2) (2024.2.0)\nDownloading rdflib-7.1.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.9/564.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\nBuilding wheels for collected packages: torch-geometric\n  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388117 sha256=9ad2982ab6191e479aaa485c49e4d174964a5fbfadb68b8ef569b713bf24bf93\n  Stored in directory: /root/.cache/pip/wheels/c0/55/79/3c3ea6134ca014b6bedf7c47797876dab8fb74774bee58c76a\nSuccessfully built torch-geometric\nInstalling collected packages: isodate, rdflib, torch-geometric\nSuccessfully installed isodate-0.7.2 rdflib-7.1.3 torch-geometric-1.7.2\nLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu121.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_cluster-1.6.3%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch-spline-conv\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (991 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m991.6/991.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2024.2.0)\nInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\nSuccessfully installed torch-cluster-1.6.3+pt25cu121 torch-scatter-2.1.2+pt25cu121 torch-sparse-0.6.18+pt25cu121 torch-spline-conv-1.2.2+pt25cu121\nCollecting deepchem\n  Downloading deepchem-2.8.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.4.2)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (2.2.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.1)\nRequirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.1)\nCollecting rdkit (from deepchem)\n  Downloading rdkit-2024.9.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21->deepchem) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21->deepchem) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21->deepchem) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21->deepchem) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21->deepchem) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21->deepchem) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (11.0.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21->deepchem) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21->deepchem) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->deepchem) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21->deepchem) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21->deepchem) (2024.2.0)\nDownloading deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading rdkit-2024.9.4-cp310-cp310-manylinux_2_28_x86_64.whl (34.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit, deepchem\nSuccessfully installed deepchem-2.8.0 rdkit-2024.9.4\nCollecting loguru\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: loguru\nSuccessfully installed loguru-0.7.3\nCollecting ase\n  Downloading ase-3.24.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from ase) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.13.1)\nRequirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from ase) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->ase) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->ase) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->ase) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->ase) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->ase) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->ase) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->ase) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.5->ase) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.5->ase) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->ase) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.5->ase) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.5->ase) (2024.2.0)\nDownloading ase-3.24.0-py3-none-any.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ase\nSuccessfully installed ase-3.24.0\n/kaggle/working/SmilesMVP/smilesmvp\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!python modeling/train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:39:30.813084Z","iopub.execute_input":"2025-01-29T09:39:30.813363Z","iopub.status.idle":"2025-01-29T13:31:27.360258Z","shell.execute_reply.started":"2025-01-29T09:39:30.813327Z","shell.execute_reply":"2025-01-29T13:31:27.359393Z"},"editable":false},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:152: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n/kaggle/working/SmilesMVP/smilesmvp/dataset.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.data, self.slices = torch.load(self.processed_paths[0])\nDataset: GEOM_3D_nmol50000_nconf5_nupper1000, Total molecules: 250000\ntokenizer_config.json: 100%|███████████████| 1.27k/1.27k [00:00<00:00, 6.09MB/s]\nconfig.json: 100%|█████████████████████████████| 631/631 [00:00<00:00, 3.23MB/s]\nvocab.json: 100%|██████████████████████████| 6.96k/6.96k [00:00<00:00, 28.4MB/s]\nmerges.txt: 100%|█████████████████████████████| 52.0/52.0 [00:00<00:00, 320kB/s]\ntokenizer.json: 100%|██████████████████████| 8.26k/8.26k [00:00<00:00, 30.7MB/s]\nadded_tokens.json: 100%|██████████████████████| 25.0/25.0 [00:00<00:00, 154kB/s]\nspecial_tokens_map.json: 100%|█████████████████| 420/420 [00:00<00:00, 2.13MB/s]\npytorch_model.bin: 100%|████████████████████| 13.7M/13.7M [00:00<00:00, 161MB/s]\nSome weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[32m2025-01-29 09:40:01.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mStarting model training...\u001b[0m\n\u001b[32m2025-01-29 09:40:01.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 1\u001b[0m\nmodel.safetensors: 100%|████████████████████| 13.7M/13.7M [00:00<00:00, 106MB/s]\n100%|█████████████████████████████████████████| 977/977 [05:04<00:00,  3.21it/s]\n\u001b[32m2025-01-29 09:45:06.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 1.56450\u001b[0m\n\u001b[32m2025-01-29 09:45:06.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 1.01659\tCL Acc: 0.80973\tAE Loss: 0.54791\u001b[0m\n\u001b[32m2025-01-29 09:45:06.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 2\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 09:50:09.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.40515\u001b[0m\n\u001b[32m2025-01-29 09:50:09.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.30759\tCL Acc: 0.94331\tAE Loss: 0.09756\u001b[0m\n\u001b[32m2025-01-29 09:50:09.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 3\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 09:55:11.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.25119\u001b[0m\n\u001b[32m2025-01-29 09:55:11.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.20328\tCL Acc: 0.96437\tAE Loss: 0.04791\u001b[0m\n\u001b[32m2025-01-29 09:55:11.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 4\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:03<00:00,  3.22it/s]\n\u001b[32m2025-01-29 10:00:14.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.18564\u001b[0m\n\u001b[32m2025-01-29 10:00:15.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.15375\tCL Acc: 0.97370\tAE Loss: 0.03189\u001b[0m\n\u001b[32m2025-01-29 10:00:15.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 5\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:05:17.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.14905\u001b[0m\n\u001b[32m2025-01-29 10:05:17.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.12304\tCL Acc: 0.97945\tAE Loss: 0.02601\u001b[0m\n\u001b[32m2025-01-29 10:05:17.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 6\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:10:20.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.12790\u001b[0m\n\u001b[32m2025-01-29 10:10:20.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.10373\tCL Acc: 0.98300\tAE Loss: 0.02416\u001b[0m\n\u001b[32m2025-01-29 10:10:20.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 7\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:15:22.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.11136\u001b[0m\n\u001b[32m2025-01-29 10:15:22.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.08833\tCL Acc: 0.98580\tAE Loss: 0.02304\u001b[0m\n\u001b[32m2025-01-29 10:15:22.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 8\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:20:24.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.09855\u001b[0m\n\u001b[32m2025-01-29 10:20:24.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.07638\tCL Acc: 0.98773\tAE Loss: 0.02217\u001b[0m\n\u001b[32m2025-01-29 10:20:24.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 9\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:03<00:00,  3.22it/s]\n\u001b[32m2025-01-29 10:25:28.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.08877\u001b[0m\n\u001b[32m2025-01-29 10:25:28.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.06733\tCL Acc: 0.98941\tAE Loss: 0.02143\u001b[0m\n\u001b[32m2025-01-29 10:25:28.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 10\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:30:30.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.07926\u001b[0m\n\u001b[32m2025-01-29 10:30:30.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.05854\tCL Acc: 0.99087\tAE Loss: 0.02071\u001b[0m\n\u001b[32m2025-01-29 10:30:30.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 11\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:03<00:00,  3.22it/s]\n\u001b[32m2025-01-29 10:35:33.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.07463\u001b[0m\n\u001b[32m2025-01-29 10:35:33.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.05410\tCL Acc: 0.99173\tAE Loss: 0.02053\u001b[0m\n\u001b[32m2025-01-29 10:35:33.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 12\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:40:36.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.06862\u001b[0m\n\u001b[32m2025-01-29 10:40:36.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.04862\tCL Acc: 0.99262\tAE Loss: 0.02000\u001b[0m\n\u001b[32m2025-01-29 10:40:36.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 13\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:45:39.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.06585\u001b[0m\n\u001b[32m2025-01-29 10:45:39.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.04592\tCL Acc: 0.99300\tAE Loss: 0.01993\u001b[0m\n\u001b[32m2025-01-29 10:45:39.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 14\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 10:50:41.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.06065\u001b[0m\n\u001b[32m2025-01-29 10:50:41.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.04080\tCL Acc: 0.99383\tAE Loss: 0.01984\u001b[0m\n\u001b[32m2025-01-29 10:50:41.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 15\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 10:55:43.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.05810\u001b[0m\n\u001b[32m2025-01-29 10:55:43.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.03835\tCL Acc: 0.99420\tAE Loss: 0.01974\u001b[0m\n\u001b[32m2025-01-29 10:55:43.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 16\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 11:00:46.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.05513\u001b[0m\n\u001b[32m2025-01-29 11:00:46.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.03533\tCL Acc: 0.99480\tAE Loss: 0.01979\u001b[0m\n\u001b[32m2025-01-29 11:00:46.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 17\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 11:05:48.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.05314\u001b[0m\n\u001b[32m2025-01-29 11:05:48.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.03358\tCL Acc: 0.99514\tAE Loss: 0.01956\u001b[0m\n\u001b[32m2025-01-29 11:05:48.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 18\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 11:10:49.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.05129\u001b[0m\n\u001b[32m2025-01-29 11:10:49.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.03124\tCL Acc: 0.99539\tAE Loss: 0.02004\u001b[0m\n\u001b[32m2025-01-29 11:10:49.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 19\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:03<00:00,  3.22it/s]\n\u001b[32m2025-01-29 11:15:53.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04934\u001b[0m\n\u001b[32m2025-01-29 11:15:53.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02953\tCL Acc: 0.99567\tAE Loss: 0.01980\u001b[0m\n\u001b[32m2025-01-29 11:15:53.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 20\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 11:20:55.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04764\u001b[0m\n\u001b[32m2025-01-29 11:20:55.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02745\tCL Acc: 0.99593\tAE Loss: 0.02019\u001b[0m\n\u001b[32m2025-01-29 11:20:55.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 21\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 11:25:57.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04751\u001b[0m\n\u001b[32m2025-01-29 11:25:57.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02742\tCL Acc: 0.99600\tAE Loss: 0.02009\u001b[0m\n\u001b[32m2025-01-29 11:25:57.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 22\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 11:30:59.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04536\u001b[0m\n\u001b[32m2025-01-29 11:30:59.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02527\tCL Acc: 0.99629\tAE Loss: 0.02009\u001b[0m\n\u001b[32m2025-01-29 11:30:59.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 23\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 11:36:02.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02516\tCL Acc: 0.99637\tAE Loss: 0.02025\u001b[0m\n\u001b[32m2025-01-29 11:36:02.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 24\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 11:41:03.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04259\u001b[0m\n\u001b[32m2025-01-29 11:41:03.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02209\tCL Acc: 0.99677\tAE Loss: 0.02049\u001b[0m\n\u001b[32m2025-01-29 11:41:03.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 25\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 11:46:06.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02289\tCL Acc: 0.99665\tAE Loss: 0.02100\u001b[0m\n\u001b[32m2025-01-29 11:46:06.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 26\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:02<00:00,  3.23it/s]\n\u001b[32m2025-01-29 11:51:09.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02181\tCL Acc: 0.99694\tAE Loss: 0.02084\u001b[0m\n\u001b[32m2025-01-29 11:51:09.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 27\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 11:56:10.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04175\u001b[0m\n\u001b[32m2025-01-29 11:56:10.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02060\tCL Acc: 0.99700\tAE Loss: 0.02115\u001b[0m\n\u001b[32m2025-01-29 11:56:10.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 28\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:01:10.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.02109\tCL Acc: 0.99701\tAE Loss: 0.02148\u001b[0m\n\u001b[32m2025-01-29 12:01:10.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 29\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 12:06:12.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04037\u001b[0m\n\u001b[32m2025-01-29 12:06:12.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01846\tCL Acc: 0.99742\tAE Loss: 0.02190\u001b[0m\n\u001b[32m2025-01-29 12:06:12.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 30\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:11:13.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01897\tCL Acc: 0.99726\tAE Loss: 0.02211\u001b[0m\n\u001b[32m2025-01-29 12:11:13.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 31\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.26it/s]\n\u001b[32m2025-01-29 12:16:13.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01834\tCL Acc: 0.99744\tAE Loss: 0.02257\u001b[0m\n\u001b[32m2025-01-29 12:16:13.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 32\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:21:14.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.04015\u001b[0m\n\u001b[32m2025-01-29 12:21:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01754\tCL Acc: 0.99749\tAE Loss: 0.02261\u001b[0m\n\u001b[32m2025-01-29 12:21:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 33\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:26:15.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01773\tCL Acc: 0.99753\tAE Loss: 0.02270\u001b[0m\n\u001b[32m2025-01-29 12:26:15.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 34\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:31:15.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01677\tCL Acc: 0.99769\tAE Loss: 0.02338\u001b[0m\n\u001b[32m2025-01-29 12:31:15.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 35\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:36:16.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01669\tCL Acc: 0.99767\tAE Loss: 0.02380\u001b[0m\n\u001b[32m2025-01-29 12:36:16.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 36\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:41:16.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mSaving best model with loss: 0.03959\u001b[0m\n\u001b[32m2025-01-29 12:41:17.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01520\tCL Acc: 0.99786\tAE Loss: 0.02439\u001b[0m\n\u001b[32m2025-01-29 12:41:17.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 37\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 12:46:18.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01611\tCL Acc: 0.99773\tAE Loss: 0.02502\u001b[0m\n\u001b[32m2025-01-29 12:46:18.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 38\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 12:51:19.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01480\tCL Acc: 0.99800\tAE Loss: 0.02512\u001b[0m\n\u001b[32m2025-01-29 12:51:19.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 39\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 12:56:20.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01420\tCL Acc: 0.99806\tAE Loss: 0.02613\u001b[0m\n\u001b[32m2025-01-29 12:56:20.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 40\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 13:01:21.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01467\tCL Acc: 0.99797\tAE Loss: 0.02639\u001b[0m\n\u001b[32m2025-01-29 13:01:21.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 41\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 13:06:22.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01336\tCL Acc: 0.99819\tAE Loss: 0.02691\u001b[0m\n\u001b[32m2025-01-29 13:06:22.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 42\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 13:11:24.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01322\tCL Acc: 0.99819\tAE Loss: 0.02803\u001b[0m\n\u001b[32m2025-01-29 13:11:24.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 43\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:00<00:00,  3.25it/s]\n\u001b[32m2025-01-29 13:16:24.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01337\tCL Acc: 0.99823\tAE Loss: 0.02790\u001b[0m\n\u001b[32m2025-01-29 13:16:24.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 44\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [04:59<00:00,  3.26it/s]\n\u001b[32m2025-01-29 13:21:24.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01346\tCL Acc: 0.99816\tAE Loss: 0.02837\u001b[0m\n\u001b[32m2025-01-29 13:21:24.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 45\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [04:59<00:00,  3.26it/s]\n\u001b[32m2025-01-29 13:26:24.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01332\tCL Acc: 0.99816\tAE Loss: 0.02849\u001b[0m\n\u001b[32m2025-01-29 13:26:24.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEpoch: 46\u001b[0m\n100%|█████████████████████████████████████████| 977/977 [05:01<00:00,  3.24it/s]\n\u001b[32m2025-01-29 13:31:25.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mCL Loss: 0.01276\tCL Acc: 0.99824\tAE Loss: 0.02945\u001b[0m\n\u001b[32m2025-01-29 13:31:25.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mEarly stopping triggered!\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install --upgrade torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T13:43:59.327429Z","iopub.execute_input":"2025-01-29T13:43:59.327718Z","iopub.status.idle":"2025-01-29T13:44:04.145829Z","shell.execute_reply.started":"2025-01-29T13:43:59.327694Z","shell.execute_reply":"2025-01-29T13:44:04.144571Z"},"editable":false},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (1.7.2)\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\n  Attempting uninstall: torch-geometric\n    Found existing installation: torch_geometric 1.7.2\n    Uninstalling torch_geometric-1.7.2:\n      Successfully uninstalled torch_geometric-1.7.2\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!python modeling/classification_finetuning.py","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-01-29T13:49:17.641613Z","shell.execute_reply.started":"2025-01-29T13:44:04.147671Z","shell.execute_reply":"2025-01-29T13:49:17.640481Z"},"editable":false},"outputs":[{"name":"stdout","text":"tokenizer_config.json: 100%|███████████████| 1.27k/1.27k [00:00<00:00, 5.71MB/s]\nconfig.json: 100%|█████████████████████████████| 631/631 [00:00<00:00, 3.63MB/s]\nvocab.json: 100%|██████████████████████████| 6.96k/6.96k [00:00<00:00, 25.2MB/s]\nmerges.txt: 100%|█████████████████████████████| 52.0/52.0 [00:00<00:00, 237kB/s]\ntokenizer.json: 100%|██████████████████████| 8.26k/8.26k [00:00<00:00, 21.5MB/s]\nadded_tokens.json: 100%|██████████████████████| 25.0/25.0 [00:00<00:00, 146kB/s]\nspecial_tokens_map.json: 100%|█████████████████| 420/420 [00:00<00:00, 2.55MB/s]\npytorch_model.bin: 100%|███████████████████| 13.7M/13.7M [00:00<00:00, 96.5MB/s]\nSome weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/kaggle/working/SmilesMVP/smilesmvp/modeling/classification_finetuning.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  chemberta.load_state_dict(torch.load(join(args.input_model_dir, '_model_final.pth'), map_location=device))\n\u001b[32m2025-01-29 13:44:37.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mLoaded pretrained model from /kaggle/input/classification-pretrained\u001b[0m\nmodel.safetensors: 100%|████████████████████| 13.7M/13.7M [00:00<00:00, 114MB/s]\n100%|█████████████████████████████████████████| 196/196 [00:05<00:00, 36.19it/s]\n\u001b[32m2025-01-29 13:44:42.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 1 | Loss: 0.36898115748653604\u001b[0m\n\u001b[32m2025-01-29 13:44:43.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.562969 | test: 0.582849\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.02it/s]\n\u001b[32m2025-01-29 13:44:48.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 2 | Loss: 0.22175808813498946\u001b[0m\n\u001b[32m2025-01-29 13:44:48.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.690421 | test: 0.646367\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.97it/s]\n\u001b[32m2025-01-29 13:44:53.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 3 | Loss: 0.1994461418718708\u001b[0m\n\u001b[32m2025-01-29 13:44:54.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.712537 | test: 0.683754\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.76it/s]\n\u001b[32m2025-01-29 13:44:59.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 4 | Loss: 0.18634923251003635\u001b[0m\n\u001b[32m2025-01-29 13:44:59.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.728534 | test: 0.719918\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.13it/s]\n\u001b[32m2025-01-29 13:45:04.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 5 | Loss: 0.1777704191223091\u001b[0m\n\u001b[32m2025-01-29 13:45:05.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.726173 | test: 0.717181\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.58it/s]\n\u001b[32m2025-01-29 13:45:10.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 6 | Loss: 0.17109615446961657\u001b[0m\n\u001b[32m2025-01-29 13:45:11.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.732157 | test: 0.737269\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.82it/s]\n\u001b[32m2025-01-29 13:45:15.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 7 | Loss: 0.16533344676147918\u001b[0m\n\u001b[32m2025-01-29 13:45:16.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.738148 | test: 0.735873\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.95it/s]\n\u001b[32m2025-01-29 13:45:21.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 8 | Loss: 0.16116285620599377\u001b[0m\n\u001b[32m2025-01-29 13:45:22.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.739099 | test: 0.738339\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 43.04it/s]\n\u001b[32m2025-01-29 13:45:26.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 9 | Loss: 0.1567298180746789\u001b[0m\n\u001b[32m2025-01-29 13:45:27.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.744314 | test: 0.741513\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.60it/s]\n\u001b[32m2025-01-29 13:45:32.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 10 | Loss: 0.15271837306113875\u001b[0m\n\u001b[32m2025-01-29 13:45:33.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.736323 | test: 0.734652\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.77it/s]\n\u001b[32m2025-01-29 13:45:37.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 11 | Loss: 0.1481238638564032\u001b[0m\n\u001b[32m2025-01-29 13:45:38.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.745317 | test: 0.738548\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.44it/s]\n\u001b[32m2025-01-29 13:45:43.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 12 | Loss: 0.14662127040934805\u001b[0m\n\u001b[32m2025-01-29 13:45:44.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.757501 | test: 0.735597\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.06it/s]\n\u001b[32m2025-01-29 13:45:48.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 13 | Loss: 0.14198768978976473\u001b[0m\n\u001b[32m2025-01-29 13:45:49.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.745697 | test: 0.726531\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.85it/s]\n\u001b[32m2025-01-29 13:45:54.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 14 | Loss: 0.13903117495379885\u001b[0m\n\u001b[32m2025-01-29 13:45:55.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.747358 | test: 0.730030\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.15it/s]\n\u001b[32m2025-01-29 13:46:00.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 15 | Loss: 0.135271212200121\u001b[0m\n\u001b[32m2025-01-29 13:46:00.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.753405 | test: 0.727237\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 40.73it/s]\n\u001b[32m2025-01-29 13:46:05.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 16 | Loss: 0.13276809370335269\u001b[0m\n\u001b[32m2025-01-29 13:46:06.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.749181 | test: 0.723291\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.13it/s]\n\u001b[32m2025-01-29 13:46:11.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 17 | Loss: 0.12939963978240077\u001b[0m\n\u001b[32m2025-01-29 13:46:12.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.749376 | test: 0.719710\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.55it/s]\n\u001b[32m2025-01-29 13:46:16.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 18 | Loss: 0.12620933753039157\u001b[0m\n\u001b[32m2025-01-29 13:46:17.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.752346 | test: 0.718144\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.07it/s]\n\u001b[32m2025-01-29 13:46:22.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 19 | Loss: 0.12402820864654317\u001b[0m\n\u001b[32m2025-01-29 13:46:23.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.753178 | test: 0.719783\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 43.06it/s]\n\u001b[32m2025-01-29 13:46:27.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 20 | Loss: 0.12136327494315956\u001b[0m\n\u001b[32m2025-01-29 13:46:28.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.754404 | test: 0.720544\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.36it/s]\n\u001b[32m2025-01-29 13:46:33.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 21 | Loss: 0.11823696076717911\u001b[0m\n\u001b[32m2025-01-29 13:46:34.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.746847 | test: 0.721297\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.29it/s]\n\u001b[32m2025-01-29 13:46:38.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 22 | Loss: 0.11605687509766038\u001b[0m\n\u001b[32m2025-01-29 13:46:39.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.752639 | test: 0.720086\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.07it/s]\n\u001b[32m2025-01-29 13:46:44.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 23 | Loss: 0.11250012480102632\u001b[0m\n\u001b[32m2025-01-29 13:46:45.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.748327 | test: 0.709919\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.75it/s]\n\u001b[32m2025-01-29 13:46:50.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 24 | Loss: 0.11027237103909862\u001b[0m\n\u001b[32m2025-01-29 13:46:51.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.751306 | test: 0.706778\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.24it/s]\n\u001b[32m2025-01-29 13:46:55.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 25 | Loss: 0.10781182688946019\u001b[0m\n\u001b[32m2025-01-29 13:46:56.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.746061 | test: 0.711604\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 43.10it/s]\n\u001b[32m2025-01-29 13:47:01.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 26 | Loss: 0.10560697347533946\u001b[0m\n\u001b[32m2025-01-29 13:47:02.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.744445 | test: 0.709277\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.89it/s]\n\u001b[32m2025-01-29 13:47:06.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 27 | Loss: 0.10255731589027814\u001b[0m\n\u001b[32m2025-01-29 13:47:07.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.745623 | test: 0.714531\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.73it/s]\n\u001b[32m2025-01-29 13:47:12.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 28 | Loss: 0.10090044861165237\u001b[0m\n\u001b[32m2025-01-29 13:47:13.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.745326 | test: 0.714570\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.44it/s]\n\u001b[32m2025-01-29 13:47:17.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 29 | Loss: 0.09716357997789675\u001b[0m\n\u001b[32m2025-01-29 13:47:18.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.747334 | test: 0.710141\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.97it/s]\n\u001b[32m2025-01-29 13:47:23.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 30 | Loss: 0.09582443972479324\u001b[0m\n\u001b[32m2025-01-29 13:47:24.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.744931 | test: 0.709964\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.78it/s]\n\u001b[32m2025-01-29 13:47:28.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 31 | Loss: 0.09283530769147436\u001b[0m\n\u001b[32m2025-01-29 13:47:29.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.741889 | test: 0.704944\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.45it/s]\n\u001b[32m2025-01-29 13:47:34.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 32 | Loss: 0.09121889725555571\u001b[0m\n\u001b[32m2025-01-29 13:47:35.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.738012 | test: 0.708505\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.64it/s]\n\u001b[32m2025-01-29 13:47:39.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 33 | Loss: 0.08839663135229933\u001b[0m\n\u001b[32m2025-01-29 13:47:40.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.745796 | test: 0.713930\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.26it/s]\n\u001b[32m2025-01-29 13:47:45.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 34 | Loss: 0.08604469083781753\u001b[0m\n\u001b[32m2025-01-29 13:47:46.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.739895 | test: 0.704617\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.45it/s]\n\u001b[32m2025-01-29 13:47:50.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 35 | Loss: 0.08327303374452251\u001b[0m\n\u001b[32m2025-01-29 13:47:51.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.738528 | test: 0.711555\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.43it/s]\n\u001b[32m2025-01-29 13:47:56.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 36 | Loss: 0.08157401997596025\u001b[0m\n\u001b[32m2025-01-29 13:47:57.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.740598 | test: 0.704411\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.59it/s]\n\u001b[32m2025-01-29 13:48:01.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 37 | Loss: 0.07827504726164804\u001b[0m\n\u001b[32m2025-01-29 13:48:02.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.744779 | test: 0.704846\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.45it/s]\n\u001b[32m2025-01-29 13:48:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 38 | Loss: 0.07811062597688667\u001b[0m\n\u001b[32m2025-01-29 13:48:08.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.739605 | test: 0.698628\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.95it/s]\n\u001b[32m2025-01-29 13:48:13.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 39 | Loss: 0.0749239265082442\u001b[0m\n\u001b[32m2025-01-29 13:48:14.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.737378 | test: 0.697842\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 43.19it/s]\n\u001b[32m2025-01-29 13:48:18.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 40 | Loss: 0.07428239394283416\u001b[0m\n\u001b[32m2025-01-29 13:48:19.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.739285 | test: 0.697630\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.76it/s]\n\u001b[32m2025-01-29 13:48:24.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 41 | Loss: 0.07174855178906298\u001b[0m\n\u001b[32m2025-01-29 13:48:24.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.734687 | test: 0.701917\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.51it/s]\n\u001b[32m2025-01-29 13:48:29.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 42 | Loss: 0.07016672150288918\u001b[0m\n\u001b[32m2025-01-29 13:48:30.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.738041 | test: 0.699899\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.32it/s]\n\u001b[32m2025-01-29 13:48:35.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 43 | Loss: 0.06745478200574158\u001b[0m\n\u001b[32m2025-01-29 13:48:35.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.731191 | test: 0.708088\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.31it/s]\n\u001b[32m2025-01-29 13:48:40.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 44 | Loss: 0.06501959749896612\u001b[0m\n\u001b[32m2025-01-29 13:48:41.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.733316 | test: 0.704172\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.47it/s]\n\u001b[32m2025-01-29 13:48:46.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 45 | Loss: 0.06468804065632272\u001b[0m\n\u001b[32m2025-01-29 13:48:46.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.738252 | test: 0.705489\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.95it/s]\n\u001b[32m2025-01-29 13:48:51.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 46 | Loss: 0.06333353350471173\u001b[0m\n\u001b[32m2025-01-29 13:48:52.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.730853 | test: 0.705754\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.89it/s]\n\u001b[32m2025-01-29 13:48:57.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 47 | Loss: 0.062214021789556255\u001b[0m\n\u001b[32m2025-01-29 13:48:58.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.727328 | test: 0.702350\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 40.60it/s]\n\u001b[32m2025-01-29 13:49:02.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 48 | Loss: 0.06038542439666938\u001b[0m\n\u001b[32m2025-01-29 13:49:03.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.731482 | test: 0.709029\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 42.36it/s]\n\u001b[32m2025-01-29 13:49:08.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 49 | Loss: 0.058737724810382544\u001b[0m\n\u001b[32m2025-01-29 13:49:09.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.727565 | test: 0.703466\u001b[0m\n100%|█████████████████████████████████████████| 196/196 [00:04<00:00, 41.47it/s]\n\u001b[32m2025-01-29 13:49:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mEpoch: 50 | Loss: 0.056475340369708686\u001b[0m\n\u001b[32m2025-01-29 13:49:14.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mval: 0.731592 | test: 0.708200\u001b[0m\n","output_type":"stream"}],"execution_count":3}]}